{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd4fa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OLIST COMBINED DATASET EXPLORATION ===\n",
      "Goal: Understand data structure, relationships, and business opportunities\n",
      "Datasets: Brazilian E-Commerce + Marketing Funnel\n",
      "Data location: Centralized data folder at project root\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Olist E-Commerce - Initial Exploration\n",
    "# Phase 1: Data Discovery and Business Understanding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path to import data_ingestion module\n",
    "project_root = Path('../').resolve()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "print(\"=== OLIST COMBINED DATASET EXPLORATION ===\")\n",
    "print(\"Goal: Understand data structure, relationships, and business opportunities\")\n",
    "print(\"Datasets: Brazilian E-Commerce + Marketing Funnel\")\n",
    "print(\"Data location: Centralized data folder at project root\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a94afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA SETUP USING CENTRALIZED INGESTION ===\n",
      "Using data_ingestion.py script for consistent data management...\n",
      "------------------------------------------------------------\n",
      "‚úì Data ingestion module imported successfully\n",
      "\n",
      "--- Checking if datasets need to be downloaded ---\n",
      "‚úì Data directory exists with expected files\n",
      "\n",
      "==================================================\n",
      "‚úÖ DATA SETUP COMPLETE!\n",
      "Data is ready for loading and analysis.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA SETUP: USE CENTRALIZED DATA INGESTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== DATA SETUP USING CENTRALIZED INGESTION ===\")\n",
    "print(\"Using data_ingestion.py script for consistent data management...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Import data ingestion functions\n",
    "try:\n",
    "    from data_ingestion import setup_kaggle_datasets, load_datasets\n",
    "    print(\"‚úì Data ingestion module imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Error: Could not import data_ingestion module\")\n",
    "    print(\"Please ensure data_ingestion.py exists in the notebooks directory\")\n",
    "    print(\"Run the following command from notebooks directory:\")\n",
    "    print(\"python data_ingestion.py\")\n",
    "    \n",
    "# Option 1: Run full data ingestion if needed\n",
    "# This will download datasets if not already present\n",
    "print(\"\\n--- Checking if datasets need to be downloaded ---\")\n",
    "data_dir = Path('../data')\n",
    "if not data_dir.exists() or len(list(data_dir.rglob(\"*.csv\"))) < 9:\n",
    "    print(\"üì• Running data ingestion (download + setup)...\")\n",
    "    setup_success = setup_kaggle_datasets()\n",
    "    if not setup_success:\n",
    "        print(\"‚ùå Data setup failed. Please run data_ingestion.py manually from notebooks directory\")\n",
    "else:\n",
    "    print(\"‚úì Data directory exists with expected files\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ DATA SETUP COMPLETE!\")\n",
    "print(\"Data is ready for loading and analysis.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2912eda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: DATA INVENTORY AND LOADING\n",
      "Loading from centralized data folder at project root...\n",
      "--------------------------------------------------\n",
      "‚úì Data folder found: ../data\n",
      "\n",
      "--- Using centralized data loading function ---\n",
      "\n",
      "=== LOADING DATASETS ===\n",
      "Loading E-Commerce dataset into memory...\n",
      "----------------------------------------\n",
      "Loading E-Commerce datasets...\n",
      "‚úì customers: 99,441 rows x 5 cols\n",
      "‚úì orders: 99,441 rows x 8 cols\n",
      "‚úì order_items: 112,650 rows x 7 cols\n",
      "‚úì order_payments: 103,886 rows x 5 cols\n",
      "‚úì order_reviews: 99,224 rows x 7 cols\n",
      "‚úì products: 32,951 rows x 9 cols\n",
      "‚úì sellers: 3,095 rows x 4 cols\n",
      "‚úì geolocation: 1,000,163 rows x 5 cols\n",
      "‚úì category_translation: 71 rows x 2 cols\n",
      "\n",
      "‚úÖ Data loading complete!\n",
      "E-Commerce datasets loaded: 9\n",
      "\n",
      "üìä DATA LOADING SUMMARY:\n",
      "E-Commerce datasets: 9 tables loaded\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: DATA INVENTORY AND LOADING FROM CENTRALIZED DATA FOLDER\n",
    "# =============================================================================\n",
    "\n",
    "print(\"STEP 1: DATA INVENTORY AND LOADING\")\n",
    "print(\"Loading from centralized data folder at project root...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define file paths - using centralized data folder\n",
    "ecommerce_path = Path('../data/')\n",
    "\n",
    "# Verify data folder exists\n",
    "if not ecommerce_path.exists():\n",
    "    print(\"‚ùå Error: Data folder not found!\")\n",
    "    print(\"Please run the data_ingestion.py script first:\")\n",
    "    print(\"cd notebooks && python data_ingestion.py\")\n",
    "else:\n",
    "    print(f\"‚úì Data folder found: {ecommerce_path}\")\n",
    "\n",
    "# Use the load_datasets function from data_ingestion module\n",
    "print(\"\\n--- Using centralized data loading function ---\")\n",
    "try:\n",
    "    # Load datasets using the centralized function\n",
    "    ecommerce_data = load_datasets()\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nüìä DATA LOADING SUMMARY:\")\n",
    "    print(f\"E-Commerce datasets: {len(ecommerce_data)} tables loaded\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error using centralized loading: {e}\")\n",
    "    print(\"Falling back to manual loading...\")\n",
    "    \n",
    "    # Fallback: Manual loading\n",
    "    # E-Commerce dataset files\n",
    "    ecommerce_files = {\n",
    "        'customers': 'olist_customers_dataset.csv',\n",
    "        'orders': 'olist_orders_dataset.csv', \n",
    "        'order_items': 'olist_order_items_dataset.csv',\n",
    "        'order_payments': 'olist_order_payments_dataset.csv',\n",
    "        'order_reviews': 'olist_order_reviews_dataset.csv',\n",
    "        'products': 'olist_products_dataset.csv',\n",
    "        'sellers': 'olist_sellers_dataset.csv',\n",
    "        'geolocation': 'olist_geolocation_dataset.csv',\n",
    "        'category_translation': 'product_category_name_translation.csv'\n",
    "    }\n",
    "    \n",
    "    # Load all datasets manually\n",
    "    print(\"Loading E-Commerce datasets...\")\n",
    "    ecommerce_data = {}\n",
    "    for name, filename in ecommerce_files.items():\n",
    "        try:\n",
    "            df = pd.read_csv(ecommerce_path / filename)\n",
    "            ecommerce_data[name] = df\n",
    "            print(f\"‚úì {name}: {df.shape[0]:,} rows x {df.shape[1]} cols\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚úó {name}: File not found - {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó {name}: Error loading - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0cd5d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: INITIAL DATA PROFILING\n",
      "\n",
      "=== PROFILING ALL E-COMMERCE DATASETS ===\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: CUSTOMERS PROFILE ===\n",
      "Shape: (99441, 5)\n",
      "Memory usage: 29.62 MB\n",
      "Columns (5 total):\n",
      "  ‚Ä¢ customer_id\n",
      "  ‚Ä¢ customer_unique_id\n",
      "  ‚Ä¢ customer_zip_code_prefix\n",
      "  ‚Ä¢ customer_city\n",
      "  ‚Ä¢ customer_state\n",
      "No null values found\n",
      "Data types: {dtype('O'): 4, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDERS PROFILE ===\n",
      "Shape: (99441, 8)\n",
      "Memory usage: 58.97 MB\n",
      "Columns (8 total):\n",
      "  ‚Ä¢ order_id\n",
      "  ‚Ä¢ customer_id\n",
      "  ‚Ä¢ order_status\n",
      "  ‚Ä¢ order_purchase_timestamp\n",
      "  ‚Ä¢ order_approved_at\n",
      "  ‚Ä¢ order_delivered_carrier_date\n",
      "  ‚Ä¢ order_delivered_customer_date\n",
      "  ‚Ä¢ order_estimated_delivery_date\n",
      "Null values:\n",
      "  order_approved_at: 160 (0.2%)\n",
      "  order_delivered_carrier_date: 1,783 (1.8%)\n",
      "  order_delivered_customer_date: 2,965 (3.0%)\n",
      "Data types: {dtype('O'): 8}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDER_ITEMS PROFILE ===\n",
      "Shape: (112650, 7)\n",
      "Memory usage: 39.43 MB\n",
      "Columns (7 total):\n",
      "  ‚Ä¢ order_id\n",
      "  ‚Ä¢ order_item_id\n",
      "  ‚Ä¢ product_id\n",
      "  ‚Ä¢ seller_id\n",
      "  ‚Ä¢ shipping_limit_date\n",
      "  ‚Ä¢ price\n",
      "  ‚Ä¢ freight_value\n",
      "No null values found\n",
      "Data types: {dtype('O'): 4, dtype('float64'): 2, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDER_PAYMENTS PROFILE ===\n",
      "Shape: (103886, 5)\n",
      "Memory usage: 17.81 MB\n",
      "Columns (5 total):\n",
      "  ‚Ä¢ order_id\n",
      "  ‚Ä¢ payment_sequential\n",
      "  ‚Ä¢ payment_type\n",
      "  ‚Ä¢ payment_installments\n",
      "  ‚Ä¢ payment_value\n",
      "No null values found\n",
      "Data types: {dtype('O'): 2, dtype('int64'): 2, dtype('float64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: ORDER_REVIEWS PROFILE ===\n",
      "Shape: (99224, 7)\n",
      "Memory usage: 42.75 MB\n",
      "Columns (7 total):\n",
      "  ‚Ä¢ review_id\n",
      "  ‚Ä¢ order_id\n",
      "  ‚Ä¢ review_score\n",
      "  ‚Ä¢ review_comment_title\n",
      "  ‚Ä¢ review_comment_message\n",
      "  ‚Ä¢ review_creation_date\n",
      "  ‚Ä¢ review_answer_timestamp\n",
      "Null values:\n",
      "  review_comment_title: 87,656 (88.3%)\n",
      "  review_comment_message: 58,247 (58.7%)\n",
      "Data types: {dtype('O'): 6, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: PRODUCTS PROFILE ===\n",
      "Shape: (32951, 9)\n",
      "Memory usage: 6.79 MB\n",
      "Columns (9 total):\n",
      "  ‚Ä¢ product_id\n",
      "  ‚Ä¢ product_category_name\n",
      "  ‚Ä¢ product_name_lenght\n",
      "  ‚Ä¢ product_description_lenght\n",
      "  ‚Ä¢ product_photos_qty\n",
      "  ‚Ä¢ product_weight_g\n",
      "  ‚Ä¢ product_length_cm\n",
      "  ‚Ä¢ product_height_cm\n",
      "  ‚Ä¢ product_width_cm\n",
      "Null values:\n",
      "  product_category_name: 610 (1.9%)\n",
      "  product_name_lenght: 610 (1.9%)\n",
      "  product_description_lenght: 610 (1.9%)\n",
      "  product_photos_qty: 610 (1.9%)\n",
      "  product_weight_g: 2 (0.0%)\n",
      "  product_length_cm: 2 (0.0%)\n",
      "  product_height_cm: 2 (0.0%)\n",
      "  product_width_cm: 2 (0.0%)\n",
      "Data types: {dtype('float64'): 7, dtype('O'): 2}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: SELLERS PROFILE ===\n",
      "Shape: (3095, 4)\n",
      "Memory usage: 0.66 MB\n",
      "Columns (4 total):\n",
      "  ‚Ä¢ seller_id\n",
      "  ‚Ä¢ seller_zip_code_prefix\n",
      "  ‚Ä¢ seller_city\n",
      "  ‚Ä¢ seller_state\n",
      "No null values found\n",
      "Data types: {dtype('O'): 3, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: GEOLOCATION PROFILE ===\n",
      "Shape: (1000163, 5)\n",
      "Memory usage: 145.20 MB\n",
      "Columns (5 total):\n",
      "  ‚Ä¢ geolocation_zip_code_prefix\n",
      "  ‚Ä¢ geolocation_lat\n",
      "  ‚Ä¢ geolocation_lng\n",
      "  ‚Ä¢ geolocation_city\n",
      "  ‚Ä¢ geolocation_state\n",
      "No null values found\n",
      "Data types: {dtype('float64'): 2, dtype('O'): 2, dtype('int64'): 1}\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== E-COMMERCE: CATEGORY_TRANSLATION PROFILE ===\n",
      "Shape: (71, 2)\n",
      "Memory usage: 0.01 MB\n",
      "Columns (2 total):\n",
      "  ‚Ä¢ product_category_name\n",
      "  ‚Ä¢ product_category_name_english\n",
      "No null values found\n",
      "Data types: {dtype('O'): 2}\n",
      "\n",
      "============================================================\n",
      "SUMMARY: Profiled 9 e-commerce datasets\n",
      "E-commerce datasets: ['customers', 'orders', 'order_items', 'order_payments', 'order_reviews', 'products', 'sellers', 'geolocation', 'category_translation']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: INITIAL DATA PROFILING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: INITIAL DATA PROFILING\")\n",
    "\n",
    "def profile_dataset(df, name):\n",
    "    \"\"\"Quick data profiling function\"\"\"\n",
    "    print(f\"\\n=== {name.upper()} PROFILE ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Display columns as bulleted list\n",
    "    print(f\"Columns ({len(df.columns)} total):\")\n",
    "    for col in df.columns:\n",
    "        print(f\"  ‚Ä¢ {col}\")\n",
    "    \n",
    "    # Null values\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        print(f\"Null values:\")\n",
    "        for col, count in null_counts[null_counts > 0].items():\n",
    "            print(f\"  {col}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No null values found\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"Data types: {df.dtypes.value_counts().to_dict()}\")\n",
    "    \n",
    "    return df.describe(include='all')\n",
    "\n",
    "# Profile ALL E-commerce datasets\n",
    "print(\"\\n=== PROFILING ALL E-COMMERCE DATASETS ===\")\n",
    "ecommerce_profiles = {}\n",
    "for dataset_name, dataset_df in ecommerce_data.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    ecommerce_profiles[dataset_name] = profile_dataset(dataset_df, f\"E-Commerce: {dataset_name}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SUMMARY: Profiled {len(ecommerce_profiles)} e-commerce datasets\")\n",
    "print(f\"E-commerce datasets: {list(ecommerce_profiles.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b15a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 3: E-COMMERCE DATA RELATIONSHIP ANALYSIS\n",
      "----------------------------------------\n",
      "E-Commerce Data Structure:\n",
      "1. Total Orders: 99,441\n",
      "2. Total Unique Customers: 96,096\n",
      "3. Total Customers with Orders: 96,096\n",
      "\n",
      "4. Customer Purchase Behavior (Based on Actual Unique Customers):\n",
      "   - One-time customers: 93,099 (96.9%)\n",
      "   - Repeat customers: 2,997 (3.1%)\n",
      "   - Max orders per unique customer: 17\n",
      "   - Average orders per unique customer: 1.03\n",
      "\n",
      "5. Order Status Distribution:\n",
      "   - delivered: 96,478 (97.0%)\n",
      "   - shipped: 1,107 (1.1%)\n",
      "   - canceled: 625 (0.6%)\n",
      "   - unavailable: 609 (0.6%)\n",
      "   - invoiced: 314 (0.3%)\n",
      "   - processing: 301 (0.3%)\n",
      "   - created: 5 (0.0%)\n",
      "   - approved: 2 (0.0%)\n",
      "\n",
      "6. Seller Activity:\n",
      "   - Total Sellers: 3,095\n",
      "   - Active Sellers (with orders): 3,095\n",
      "   - Seller Activity Rate: 100.0%\n",
      "\n",
      "7. Customer Geographic Distribution (Top 10 States):\n",
      "   - SP: 41,746 (42.0%)\n",
      "   - RJ: 12,852 (12.9%)\n",
      "   - MG: 11,635 (11.7%)\n",
      "   - RS: 5,466 (5.5%)\n",
      "   - PR: 5,045 (5.1%)\n",
      "   - SC: 3,637 (3.7%)\n",
      "   - BA: 3,380 (3.4%)\n",
      "   - DF: 2,140 (2.2%)\n",
      "   - ES: 2,033 (2.0%)\n",
      "   - GO: 2,020 (2.0%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: E-COMMERCE DATA RELATIONSHIP ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: E-COMMERCE DATA RELATIONSHIP ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Analyze key relationships in the e-commerce data\n",
    "if 'orders' in ecommerce_data and 'customers' in ecommerce_data:\n",
    "    orders_df = ecommerce_data['orders']\n",
    "    customers_df = ecommerce_data['customers']\n",
    "    \n",
    "    print(\"E-Commerce Data Structure:\")\n",
    "    print(f\"1. Total Orders: {orders_df.shape[0]:,}\")\n",
    "    \n",
    "    # Based on Kaggle documentation\n",
    "    # customer_id: key to orders dataset (each order has unique customer_id)\n",
    "    # customer_unique_id: unique identifier of actual customers\n",
    "    total_unique_customers = customers_df['customer_unique_id'].nunique()\n",
    "    \n",
    "    # To calculate customers with orders, we need to map customer_id to customer_unique_id\n",
    "    # Create mapping from customer_id to customer_unique_id\n",
    "    customer_mapping = customers_df[['customer_id', 'customer_unique_id']].set_index('customer_id')['customer_unique_id']\n",
    "    \n",
    "    # Map orders to actual unique customers\n",
    "    orders_with_unique_customers = orders_df.copy()\n",
    "    orders_with_unique_customers['customer_unique_id'] = orders_with_unique_customers['customer_id'].map(customer_mapping)\n",
    "    \n",
    "    # Count unique customers who have orders\n",
    "    customers_with_orders = orders_with_unique_customers['customer_unique_id'].nunique()\n",
    "    \n",
    "    print(f\"2. Total Unique Customers: {total_unique_customers:,}\")\n",
    "    print(f\"3. Total Customers with Orders: {customers_with_orders:,}\")\n",
    "    \n",
    "    # Analyze customer order frequency based on actual unique customers\n",
    "    unique_customer_order_counts = orders_with_unique_customers.groupby('customer_unique_id').size()\n",
    "    repeat_customers = (unique_customer_order_counts > 1).sum()\n",
    "    one_time_customers = (unique_customer_order_counts == 1).sum()\n",
    "    \n",
    "    print(f\"\\n4. Customer Purchase Behavior (Based on Actual Unique Customers):\")\n",
    "    print(f\"   - One-time customers: {one_time_customers:,} ({one_time_customers/customers_with_orders*100:.1f}%)\")\n",
    "    print(f\"   - Repeat customers: {repeat_customers:,} ({repeat_customers/customers_with_orders*100:.1f}%)\")\n",
    "    print(f\"   - Max orders per unique customer: {unique_customer_order_counts.max()}\")\n",
    "    print(f\"   - Average orders per unique customer: {unique_customer_order_counts.mean():.2f}\")\n",
    "    \n",
    "    # Order status distribution\n",
    "    if 'order_status' in orders_df.columns:\n",
    "        print(f\"\\n5. Order Status Distribution:\")\n",
    "        status_counts = orders_df['order_status'].value_counts()\n",
    "        for status, count in status_counts.items():\n",
    "            percentage = count / len(orders_df) * 100\n",
    "            print(f\"   - {status}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Check seller information\n",
    "if 'sellers' in ecommerce_data and 'order_items' in ecommerce_data:\n",
    "    sellers_df = ecommerce_data['sellers']\n",
    "    order_items_df = ecommerce_data['order_items']\n",
    "    \n",
    "    total_sellers = sellers_df['seller_id'].nunique()\n",
    "    active_sellers = order_items_df['seller_id'].nunique()\n",
    "    print(f\"\\n6. Seller Activity:\")\n",
    "    print(f\"   - Total Sellers: {total_sellers:,}\")\n",
    "    print(f\"   - Active Sellers (with orders): {active_sellers:,}\")\n",
    "    if total_sellers > 0:\n",
    "        activity_rate = (active_sellers / total_sellers * 100)\n",
    "        print(f\"   - Seller Activity Rate: {activity_rate:.1f}%\")\n",
    "\n",
    "# Geographic distribution\n",
    "if 'customers' in ecommerce_data:\n",
    "    print(f\"\\n7. Customer Geographic Distribution (Top 10 States):\")\n",
    "    customer_state_counts = ecommerce_data['customers']['customer_state'].value_counts().head(10)\n",
    "    for state, count in customer_state_counts.items():\n",
    "        percentage = count / len(ecommerce_data['customers']) * 100\n",
    "        print(f\"   - {state}: {count:,} ({percentage:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
